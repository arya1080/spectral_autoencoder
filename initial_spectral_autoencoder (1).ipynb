{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55060380",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eacf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# for reading and displaying images\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, Sigmoid, CrossEntropyLoss, Sequential, Conv2d, ConvTranspose2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ade42d",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2770ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "data_dir = '/home/arya1080/engrprojects/WilsonGroup/TuCo/data/20210920 modify SVD_mods_Arya/620nm/'\n",
    "filenames = os.listdir(data_dir)\n",
    "# print(filenames)\n",
    "img_stack = []\n",
    "for files in filenames:\n",
    "    img = io.imread(data_dir + files)\n",
    "    plt.imshow(img[:,:,5], cmap='gray')\n",
    "#     plt.show()\n",
    "    img_stack.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddaad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert images to numpy arrays\n",
    "img_stack = np.asarray(img_stack)\n",
    "img_stack = img_stack.astype('float32')\n",
    "print(img_stack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7830b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a slice and show\n",
    "plt.imshow(img_stack[2,:,:,5], cmap = 'gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a4a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image height and width metrics\n",
    "_, nx, ny, nch = img_stack.shape\n",
    "print('img width = {}, img height = {}, img channels = {}'.format(nx, ny, nch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d88130b",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb0d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cnn_layers = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            Conv2d(nch, 64, kernel_size=3, stride=1, padding=1),\n",
    "            ReLU(inplace=True),\n",
    "            \n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            ReLU(inplace=True),\n",
    "            \n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(64, 64, kernel_size=1, stride=1),\n",
    "            ReLU(inplace=True),\n",
    "            \n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(64, 64, kernel_size=1, stride=1),\n",
    "            ReLU(inplace=True),\n",
    "            \n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(64, 3, kernel_size=1, stride=1),\n",
    "            Sigmoid()\n",
    "        )\n",
    "        \n",
    "        \"\"\"The spectral autoencoder has a bottleneck in the number of channels instead of upsampling and downsampling layers\"\"\"\n",
    "        self.cnn_spectral_layers = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            Conv2d(3, 64, kernel_size=1, stride=1),\n",
    "            ReLU(inplace=True),\n",
    "            \n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(64, nch, kernel_size=1, stride=1),            \n",
    "            \n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = self.cnn_spectral_layers(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_enc(self, x):\n",
    "        z = self.cnn_layers(x)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1789c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model by calling the function\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba74f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ddc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the model training device\n",
    "\"\"\"cuda:0 for GPU 0, cuda:1 for GPU1, cpu for CPU\"\"\"\n",
    "device = 'cuda:0'\n",
    "print(device)\n",
    "model.to(device) # load the model in the training device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c166b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the input data before training\n",
    "img_stack = torch.tensor(img_stack)\n",
    "print(img_stack.shape)\n",
    "img_stack = img_stack.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd41b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define latent space visualization function\n",
    "def visualize_z(ind):\n",
    "    data = img_stack[ind,:,:,:]\n",
    "    data = data[None,:]\n",
    "    data = data.to(device)\n",
    "    out = model.forward_enc(torch.permute(data, (0, 3, 1, 2)))\n",
    "    out = out[0,:,:,:]\n",
    "    out = torch.permute(out, (1,2,0))\n",
    "    img = out.detach().cpu().numpy()\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a233429",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb7bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10000\n",
    "L1_loss = []\n",
    "z_imgs = []\n",
    "\n",
    "for epoch in tqdm(range(1, n_epochs+1)):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "\n",
    "    #Training\n",
    "    for images in img_stack:\n",
    "        images = images[None, :]\n",
    "        image_x_p = torch.permute(images, (0, 3, 1, 2))\n",
    "        image_x_p = image_x_p.to(device)\n",
    "        optimizer.zero_grad()         \n",
    "        outputs = model(image_x_p)\n",
    "        loss = criterion(outputs, image_x_p)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*image_x_p.size(0)\n",
    "          \n",
    "    train_loss = train_loss/len(img_stack)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "    L1_loss.append(train_loss)\n",
    "    \n",
    "    if epoch%50 == 0:\n",
    "        # visualize latent space\n",
    "        temp_img = visualize_z(3)\n",
    "        z_imgs.append(temp_img)\n",
    "        # plot loss curve\n",
    "        plt.plot(L1_loss)\n",
    "        plt.title('Train Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('L1 Loss')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c583e",
   "metadata": {},
   "source": [
    "# Analyze latent space images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7104d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_imgs = np.asarray(z_imgs)\n",
    "print(z_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad07ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(z_imgs[39,:,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ebc970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the latent space image stack and save the images\n",
    "n_count = 0\n",
    "for img in z_imgs:\n",
    "    io.imsave('img' + str(n_count) + '.png', img)\n",
    "    n_count = n_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebbbeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the saved latent space images to create a movie\n",
    "image_folder = '/home/arya1080/python_projects/CNN_TAM'\n",
    "video_name = 'video.avi'\n",
    "\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "video = cv2.VideoWriter(video_name, 0, 1, (width,height))\n",
    "\n",
    "for image in images:\n",
    "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
