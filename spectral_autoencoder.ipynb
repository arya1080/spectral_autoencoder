{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# for reading and displaying images\n",
    "from skimage import io\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, Tanh, Hardtanh, LeakyReLU, ELU, Sigmoid, CrossEntropyLoss, Sequential, Conv2d, ConvTranspose2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.nn.utils import spectral_norm\n",
    "import torch.nn.functional as f\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "from scipy.stats import mode\n",
    "from scipy import stats, optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = os.uname()\n",
    "username = os.getlogin()\n",
    "global device\n",
    "if data[1] == 'lambda-dual':\n",
    "    device = 'cuda:1'\n",
    "    print('The model will be trained on {}'.format(device))\n",
    "    data_dir = '/home/'+username+'/engrprojects/WilsonGroup/TuCo/data/20210920 modify SVD_mods_Arya/620nm/'\n",
    "    save_dir = '/home/'+username+'/engrprojects/WilsonGroup/MRA_grant/work_in_progress_arya/spectral_autoencoder_data/'\n",
    "    print('Data will be loaded from \"{}\"'.format(data_dir))\n",
    "    print('Data will be saved to \"{}\"'.format(save_dir))\n",
    "elif data[1] == 'linuxg3' or data[1] == 'linuxg4':\n",
    "    device = 'cuda:0'\n",
    "    data_dir = '/top/projects/WilsonGroup/TuCo/data/20210920 modify SVD_mods_Arya/620nm/'\n",
    "    save_dir = '/top/projects/WilsonGroup/MRA_grant/work_in_progress_arya/spectral_autoencoder_data/'\n",
    "    print('The model will be trained on {}'.format(device))\n",
    "    print('Data will be saved to \"{}\"'.format(save_dir))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthogonalColorPalette( n ):\n",
    "    # generates a list of n colors, with even hue angle spacing between\n",
    "    h = np.linspace(0,1,n+1)[0:-1]  # evenly spaced hue angles\n",
    "    s = np.ones_like(h)             # saturation = 1 \n",
    "    v = s                           # value = 1\n",
    "    hsv = np.stack((h,s,v)).T       # hue-sat-value vectors\n",
    "    M = hsv_to_rgb(hsv)             # convert to RGB\n",
    "    \n",
    "    return M\n",
    "\n",
    "    \n",
    "def abundancemapToRGB( z ):\n",
    "    # (JWW 20221208 jesse.wilson@colostate.edu)\n",
    "    # inspired by Du, et al., \"Color Display for Hyperspectral Imagery\",\n",
    "    #             IEEE Trans Geosci and Remote Sens,. v46 no6 (2008).\n",
    "    \n",
    "    # generate a color palatte M, one for each endmember,\n",
    "    # where colors are spaced evely around the color wheel\n",
    "    ny, nx, nch = z.shape\n",
    "    M = orthogonalColorPalette(nch)\n",
    "    \n",
    "    # the RGB images is simply the tensor dot product between the \n",
    "    # abundance map and the color palette,\n",
    "    # summing over the abundance map's channel axis and \n",
    "    # over the color palette's index axis\n",
    "    rgb = np.tensordot(z,M,(2,0))\n",
    "    \n",
    "    return rgb\n",
    "    \n",
    "def plotEndmembers( t, w, ax=None ):\n",
    "    nt, nch = w.shape\n",
    "    M = orthogonalColorPalette(nch)\n",
    "    \n",
    "    if ax==None:\n",
    "        ax=plt.axes()\n",
    "    ax.set_facecolor('black')\n",
    "\n",
    "    for i in range(nch):\n",
    "        plt.plot(t,w[:,i],color=M[i,:])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset (CSU mito pump-probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "filenames = os.listdir(data_dir)\n",
    "img_stack = []\n",
    "for files in filenames:\n",
    "    img = io.imread(data_dir + files)\n",
    "    img_stack.append(img)\n",
    "\n",
    "# convert images to numpy arrays\n",
    "img_stack = np.asarray(img_stack)\n",
    "img_stack = img_stack.astype('float32')\n",
    "\n",
    "# get image height and width metrics\n",
    "nimg, nx, ny, nch = img_stack.shape\n",
    "print('Input dataset specs:')\n",
    "print('n. images = {}, img width = {}, img height = {}, img channels = {}'.format(nimg, nx, ny, nch))\n",
    "\n",
    "# process the input image stack\n",
    "img_stack = torch.tensor(img_stack)\n",
    "img_stack = img_stack.to(device)\n",
    "\n",
    "\n",
    "# make sure we have an even number of pixels in width and height\n",
    "# so that downsampling/upsampling will work correctly\n",
    "if nx % 2:\n",
    "    img_stack = img_stack[:,0:(nx-1),:,:]\n",
    "if ny % 2:\n",
    "    img_stack = img_stack[:,:,0:(ny-1),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch_data(img_stack, batch_size, patch_size):\n",
    "    batch_stack = []\n",
    "    for i in range(0,batch_size):\n",
    "        transform = transforms.RandomCrop((patch_size, patch_size))\n",
    "        img_stack_p = torch.permute(img_stack, (0, 3, 1, 2))\n",
    "        image_crop = transform(img_stack_p[random.randint(0,22),:,:,:])\n",
    "#         print(image_crop.size)\n",
    "        image_crop = torch.permute(image_crop, (1,2,0))\n",
    "        batch_stack.append(image_crop)\n",
    "    return batch_stack\n",
    "\n",
    "def sort_tuple(data):\n",
    "    data.sort(key = lambda x : x[0])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = img_stack[:,:,:,0].squeeze().cpu().numpy()\n",
    "np.mean(noise)\n",
    "hist,edges = np.histogram(noise, 512)\n",
    "plt.plot(edges[1:],hist)\n",
    "plt.xlim([-.1,.1])\n",
    "plt.show()\n",
    "print('noise std=  ',np.std(noise))\n",
    "print('noise mean abs = ', np.mean(np.abs(noise)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset (Duke pigmented lesions)\n",
    "These are stored as Mathematica .erg format. This code takes David Grass's sample code and wraps it as a pytorch Dataset, following the pytorch tutorial https://pytorch.org/tutorials/beginner/basics/data_tutorial.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DukeMathematicaDataset(Dataset):\n",
    "    def __init__(self, img_dir):\n",
    "        self.img_dir = img_dir\n",
    "        \n",
    "        dirlisting = os.listdir(img_dir)\n",
    "        self.file_names = []\n",
    "        for filename in dirlisting:\n",
    "            if filename.endswith('.erg'):\n",
    "                self.file_names.append(filename)\n",
    "        \n",
    "        self.t = None\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_path = os.path.join(self.img_dir,self.file_names[idx])\n",
    "        \n",
    "        # open file as read-binary with no buffering\n",
    "        f = open(img_path, 'rb')\n",
    "\n",
    "        # import first three int16 which are the time, x and y dimension\n",
    "        # convert dim to int64, because int16 is not big enougth for\n",
    "        # multiplications\n",
    "        dim = np.fromfile(f, dtype=np.int16, count=3)\n",
    "        dim = dim.astype(np.int64)\n",
    "\n",
    "        # import the time axis\n",
    "        self.t = np.fromfile(f, dtype=np.float64, count=dim[0])\n",
    "\n",
    "        # import stack, loop over time dimension dim[0] and reshape to image\n",
    "        # dimensions\n",
    "        images = np.zeros((dim[0],dim[1],dim[2]),dtype=np.float32)\n",
    "        for i in range(dim[0]):\n",
    "            temp = np.fromfile(f, dtype=np.float64, count=dim[1]*dim[2])\n",
    "            images[i,:,:] = temp.reshape((dim[1], dim[2])).astype('float32')\n",
    "\n",
    "        # close file\n",
    "        f.close\n",
    "        \n",
    "        images = torch.tensor(images)\n",
    "        images = images.to(device)\n",
    "        \n",
    "        return images\n",
    "    \n",
    "    def get_t(self):\n",
    "        # returns time sampling (probe delay) vector for most recently loaded item\n",
    "        return self.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/'+username+'/engrprojects/WilsonGroup/hyperspectralCNN/duke_data_20230413/'\n",
    "\n",
    "dataset = DukeMathematicaDataset(data_dir)\n",
    "dataset[0].type\n",
    "dataset.get_t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display an image stack for testing\n",
    "img = dataset[200].cpu().numpy()\n",
    "#max_value = np.max(np.abs(img))\n",
    "max_value = 4\n",
    "for i in range(len(img)):\n",
    "    plt.imshow(img[i])\n",
    "    plt.clim([-max_value, max_value])\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    clear_output(wait=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate synthetic endmembers\n",
    "nstacks = 100\n",
    "t=np.array([-2,0,0.2,0.4,1,2,4,6,14])[None,:]\n",
    "tau=np.array([1,2,3,4,5,6])[:,None]\n",
    "nch = 9\n",
    "w = np.exp(-t/tau)*(t>=0)\n",
    "\n",
    "# generate synthetic abundance maps\n",
    "ny = 256\n",
    "nx = 256\n",
    "blur = 15 # amount of Gaussian blur to apply\n",
    "\n",
    "nRow = 3\n",
    "nCol = 3\n",
    "margin = 8\n",
    "boxWidth = nx//nCol\n",
    "boxHeight = ny//nRow\n",
    "img_stack = []\n",
    "\n",
    "for k in range(nstacks):\n",
    "\n",
    "    z = np.zeros((256,256,len(tau)))\n",
    "    for j in range(len(tau)):\n",
    "        for i in range(9):\n",
    "            # for each square\n",
    "            x = (i % 3)*(nx//nCol)\n",
    "            y = (i//3)*(ny//nRow)\n",
    "\n",
    "            if i == j:\n",
    "                val = 1\n",
    "            elif i >= len(tau):\n",
    "                val = np.random.rand() / len(tau)\n",
    "            else:\n",
    "                val = 0;\n",
    "\n",
    "            z[(y+margin//2):(y+boxHeight-margin//2),(x+margin//2):(x+boxWidth-margin//2),j] = val\n",
    "            \n",
    "    z = transforms.functional.gaussian_blur(torch.Tensor(z).permute((2,0,1)),blur).permute((1,2,0)).numpy()\n",
    "    x = np.matmul(z,w)\n",
    "    x = x + 0.011*np.random.randn(256,256,9)\n",
    "    img_stack.append(x.astype('float32'))\n",
    "\n",
    "\n",
    "img_stack = torch.tensor(img_stack)\n",
    "img_stack = img_stack.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,2])\n",
    "ax = plt.subplot2grid((1,3),(0,0),colspan=2)\n",
    "plotEndmembers(t.squeeze(),w.T,ax)\n",
    "plt.subplot2grid((1,3),(0,2))\n",
    "plt.imshow(abundancemapToRGB(z))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(z.shape)\n",
    "print(w.shape)\n",
    "plt.figure(figsize=[6,6])\n",
    "for i in range(t.size):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(img_stack[3][:,:,i].detach().cpu().numpy())\n",
    "    plt.clim([0,1])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(Module):\n",
    "    def __init__(self, channels, kernel_size, stride, padding):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv = Sequential(\n",
    "                        Conv2d(in_channels=channels, \n",
    "                          out_channels=channels,\n",
    "                          kernel_size=kernel_size,\n",
    "                          stride=stride,\n",
    "                          padding=padding, bias=False) )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        intermediate = self.conv(x)\n",
    "        out = x + intermediate\n",
    "        return out\n",
    "        \n",
    "\n",
    "class ScalableSat(Module):\n",
    "    def __init__(self):\n",
    "        super(ScalableSat, self).__init__()\n",
    " \n",
    "        self.a = nn.parameter.Parameter(torch.Tensor([1.0,1.0,0.0]))\n",
    "        self.tanh = Hardtanh()\n",
    "        #self.tanh = Tanh()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.a[1]*self.tanh(self.a[0]*x)+self.a[2]\n",
    "    \n",
    "class LeakyHardsigmoid(Module):\n",
    "    def __init__(self, negative_slope=0.1):\n",
    "        super(LeakyHardsigmoid,self).__init__()\n",
    "        self.ns = negative_slope\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return f.leaky_relu(-f.leaky_relu(-(x-3)/6,negative_slope=self.ns)+1,negative_slope=self.ns)\n",
    "\n",
    "class OffsetHardsigmoid(Module):\n",
    "    def __init__(self):\n",
    "        super(OffsetHardsigmoid,self).__init__()\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        return f.hardsigmoid(x-3)\n",
    "\n",
    "class OffsetLeakyHardsigmoid(Module):\n",
    "    def __init__(self):\n",
    "        super(OffsetLeakyHardsigmoid,self).__init__()\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        return f.rrelu(-f.rrelu(-(x-1),lower=0)+1,lower=0)\n",
    "    \n",
    "class AbsActivation(Module):\n",
    "    def __init__(self):\n",
    "        super(AbsActivation,self).__init__()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return torch.abs(x)\n",
    "\n",
    "class NormalizeEndmembers(Module):\n",
    "    def forward(self,X):\n",
    "        return X / X.norm(dim=0)\n",
    "            \n",
    "class Net(Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        w=32\n",
    "        self.cnn_layers = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            Conv2d(nch, w, kernel_size=3, stride=1, padding=1,bias=False),\n",
    "            ReLU(),\n",
    "#             BatchNorm2d(64),\n",
    "#             Dropout(0.2),\n",
    "            Conv2d(w, w, kernel_size=1, stride=1, padding=0,bias=False),\n",
    "            ReLU(),\n",
    "#             BatchNorm2d(64),\n",
    "#             Dropout(0.2),\n",
    "            Conv2d(w, w, kernel_size=1, stride=1, padding=0,bias=False),\n",
    "            ReLU(),\n",
    "#             BatchNorm2d(64),\n",
    "#             Dropout(0.2),\n",
    "            Conv2d(w, w, kernel_size=1, stride=1, padding=0,bias=False),\n",
    "            ReLU(),\n",
    "#             BatchNorm2d(64),\n",
    "#             Dropout(0.2),\n",
    "            Conv2d(w, w, kernel_size=1, stride=1, padding=0,bias=False),\n",
    "            ReLU(),\n",
    "#             BatchNorm2d(64),\n",
    "#             Dropout(0.2),\n",
    "            \n",
    "            # Defining additional 2D convolution layer\n",
    "            Conv2d(w, nch_bottleneck, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            \n",
    "#             nn.Sigmoid(),\n",
    "            # implementing the v-notch nonlinearity\n",
    "            nn.Hardtanh(),\n",
    "            AbsActivation()\n",
    "            #ReLU()\n",
    "        )\n",
    "        \n",
    "        self.cnn_spectral_layers = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            Conv2d(nch_bottleneck, nch, kernel_size=1, stride=1,bias=False),  \n",
    "            ScalableSat()\n",
    "        )\n",
    "       \n",
    "        \n",
    "        self.cnn_layers.apply(initialize_weights_kaiming)\n",
    "        self.cnn_spectral_layers.apply(initialize_weights_kaiming)\n",
    "        #self.cnn_spectral_layers.apply(initialize_weights_endmembers)\n",
    "    \n",
    "        nn.utils.parametrize.register_parametrization(self.cnn_spectral_layers[0],\"weight\",NormalizeEndmembers())\n",
    "        \n",
    "        \n",
    "        \n",
    "    def getSOEMlayer(self):\n",
    "        return self.cnn_spectral_layers[0]\n",
    "    \n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        z = self.cnn_layers(x)\n",
    "        y = self.cnn_spectral_layers(z)\n",
    "        return y\n",
    "    \n",
    "    def forward_enc(self, x):\n",
    "        z = self.cnn_layers(x)\n",
    "\n",
    "        return z\n",
    "    \n",
    "    def forward_dec(self, z):\n",
    "        y = self.cnn_spectral_layers(z)\n",
    "        #y = self.cnn_spectral_layers(z + 0.1*torch.randn_like(z))\n",
    "        return y\n",
    "    \n",
    "def initialize_weights_kaiming(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight.data)\n",
    "        \n",
    "def initialize_weights_endmembers(m):\n",
    "    # brownian bridge\n",
    "    # brownian motion that starts and ends on zero, matching realistic constraints for transient responses\n",
    "    # equation credit: Diego Krapf\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.normal_(m.weight.data,mean=10.)\n",
    "        #nn.init.uniform_(m.weight.data)\n",
    "        with torch.no_grad():\n",
    "            m.weight.data = torch.cumsum(m.weight.data,dim=0)\n",
    "            m.weight.data[0,:]=0\n",
    "            m.weight.data = m.weight.data - torch.linspace(0,1,nch)[:,None,None,None]*m.weight.data[-1,:]\n",
    "\n",
    "        \n",
    "\n",
    "# define latent space visualization function\n",
    "def visualize_z(ind):\n",
    "    data = dataset[ind]\n",
    "    data = data[None,:]\n",
    "    data = data.to(device)\n",
    "    out = model.forward_enc(data)\n",
    "    out = out[0,:,:,:]\n",
    "    out = torch.permute(out, (1,2,0))\n",
    "    img = out.detach().cpu().numpy()\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(1.2*img[:,:,0:3])\n",
    "    plt.show()\n",
    "    return img\n",
    "\n",
    "# define latent space visualization function\n",
    "def generate_z_image(model, ind, indices):\n",
    "    data = dataset[ind]\n",
    "    data = data[None,:]\n",
    "    data = data.to(device)\n",
    "    out = model.forward_enc(data)\n",
    "    out = out[0,indices,:,:]\n",
    "    out = torch.permute(out, (1,2,0))\n",
    "    img = out.detach().cpu().numpy()\n",
    "    img = abundancemapToRGB(img)\n",
    "    return 1.*img\n",
    "\n",
    "def visualSummary(model, L1_loss, indices):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(2,3,(1,4))\n",
    "    img1 = generate_z_image(model,0, indices)\n",
    "    plt.imshow(img1)\n",
    "    plt.subplot(2,3,(2,5))\n",
    "    img2 = generate_z_image(model,1, indices)\n",
    "    plt.imshow(img2)\n",
    "    ax = plt.subplot(2,3,3)\n",
    "    w = model.getSOEMlayer().weight\n",
    "    w = w[:,indices,:,:]\n",
    "    w = w.detach().cpu().numpy().squeeze()\n",
    "    #tau=np.array([-2,0,0.2,0.4,1,2,4,6,14])\n",
    "    tau = dataset.get_t()\n",
    "    plotEndmembers(tau,w,ax)\n",
    "    plt.title('recovered endmembers')\n",
    "    plt.xlabel('probe delay, ps')\n",
    "    plt.subplot(2,3,6)\n",
    "    plt.plot(L1_loss)\n",
    "    plt.title('Train Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('L1 Loss')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return img1, img2\n",
    "    \n",
    "# Custom Loss Functions\n",
    "def meansq(x):\n",
    "    return torch.mean((x-torch.mean(x))**2)\n",
    "\n",
    "def corr(x,y):\n",
    "    return torch.sum(x*y) / (torch.sqrt(torch.sum(x**2))*torch.sqrt(torch.sum(y**2)))\n",
    "\n",
    "def SADLoss(weights):\n",
    "    deriv = torch.nn.Parameter(weights[1:,]-weights[:-1,])\n",
    "    sad = torch.sum(deriv**2)\n",
    "    return sad\n",
    "\n",
    "def channelCorrelationLoss(z):\n",
    "    # inter-channel correlation loss\n",
    "    zvec = z.squeeze().view(nch_bottleneck,-1)\n",
    "    zvec = zvec-torch.mean(zvec,1,keepdim=True)\n",
    "    zcov = torch.matmul(zvec,zvec.transpose(0,1))\n",
    "    zstds = torch.sqrt(zcov.diag()).expand(1,-1)\n",
    "    zstdprods = torch.matmul(zstds.transpose(0,1),zstds)\n",
    "    zcorrabs = zcov / (zstdprods + 1e-6)\n",
    "    #zcorrabs = torch.max(zcorrabs, torch.tensor(0.5))\n",
    "    loss_zcorr = (torch.sum((zcorrabs.triu())) - zcorrabs.trace())\n",
    "    #loss_zcorr = (torch.sum(f.relu(zcorrabs.triu())) - zcorrabs.trace())\n",
    "    #loss_zcorr += (torch.sum(f.relu(zcov.triu())) - zcov.trace())\n",
    "    #loss_zcorr = (torch.sum((zcorrabs.triu())) - zcorrabs.trace())\n",
    "    \n",
    "    return loss_zcorr\n",
    "\n",
    "def channelCrossEntropyLoss(z):\n",
    "    zvec = z.squeeze().view(nch_bottleneck,-1)\n",
    "    print(zvec.shape)\n",
    "    loss = f.cross_entropy(zvec[None,0,:],zvec[None,1,:])\n",
    "    loss += f.cross_entropy(zvec[0,:],zvec[2,:])\n",
    "    loss += f.cross_entropy(zvec[1,:],zvec[2,:])\n",
    "    loss = -1.0 * loss\n",
    "    return loss\n",
    "\n",
    "    \n",
    "\n",
    "# model training routine definition\n",
    "def train_model(model, n_epochs, dataset, lr):\n",
    "    \n",
    "    # define loss function\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # define optimizer\n",
    "    #optimizer = torch.optim.Adam([{'params':model.cnn_layers.parameters()},\n",
    "    #                              {'params':model.cnn_spectral_layers.parameters(),'lr':lr/10.}],\n",
    "    #                             lr,amsgrad=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr)\n",
    "    #optimizer = torch.optim.AdamW(model.parameters(),lr)\n",
    "    #optimizer=torch.optim.RMSprop(model.parameters(),lr)\n",
    "    #optimizer = torch.optim.Adadelta(model.parameters(),lr)\n",
    "    #optimizer = torch.optim.Adagrad(model.parameters(),lr)\n",
    "    #optimizer = torch.optim.SGD(model.parameters(),lr)\n",
    "    \n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min',factor=0.9)\n",
    "    #scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer,lr_lambda= lambda epoch: 0.99)\n",
    "    #scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=n_epochs,eta_min=0)\n",
    "    #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr=0.01,total_steps=n_epochs*len(img_stack))\n",
    "    #scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer,50)\n",
    "    \n",
    "    \n",
    "    # initialize model weights and send to train device\n",
    "    model.to(device) # load the model in the training device\n",
    "    \n",
    "    # apply initialization\n",
    "    \n",
    "    # define variables\n",
    "    total_loss = []\n",
    "    \n",
    "        \n",
    "    # iterate over the epochs\n",
    "    for epoch in tqdm(range(1, n_epochs+1)):\n",
    "        \n",
    "        # monitor training loss\n",
    "        train_loss = 0.0\n",
    "        loss_recon_avg = 0.\n",
    "        loss_zcorr_avg = 0.\n",
    "        \n",
    "        # keep track of meansq value for each channel\n",
    "        channelmsq = torch.zeros(nch_bottleneck).to(device)\n",
    "        \n",
    "        #Training       \n",
    "#         current_batch = load_batch_data(img_stack, 150, patch_size)\n",
    "        \n",
    "        #img_stack_shuffle  = img_stack[torch.randperm(len(img_stack))]\n",
    "        for image in dataset:\n",
    "            #image_x_p = torch.permute(images, (0, 3, 1, 2))\n",
    "            image_x_p = image[None,:]\n",
    "            image_x_p = image_x_p.to(device)\n",
    "            optimizer.zero_grad()   \n",
    "            z = model.forward_enc(image_x_p)\n",
    "            outputs = model.forward_dec(z)\n",
    "            \n",
    "\n",
    "            # calculate the weighted spectral angular divergence (SAD) loss\n",
    "    #             in_product = torch.sum(torch.mul(image_x_p, outputs), dim = 1)\n",
    "    #             self_product = torch.sqrt(torch.sum(torch.mul(image_x_p, image_x_p), dim = 1)) * torch.sqrt(torch.sum(torch.mul(outputs, outputs), dim =1))            \n",
    "    #             cos_theta = torch.div(in_product, self_product)\n",
    "    #             theta = torch.acos(cos_theta)\n",
    "    #             mSAD = torch.mean(theta)\n",
    "\n",
    "    #             cos = nn.CosineSimilarity(dim=1, eps=1e-8)\n",
    "    #             cos_loss = torch.mean(torch.acos(cos(image_x_p, outputs)))\n",
    "\n",
    "            # variance-ordering\n",
    "            channelmsq += torch.mean(z**2,dim=[2,3]).squeeze()\n",
    "\n",
    "            # stack sum-squared\n",
    "            ssq = torch.sum(image_x_p**2, dim = 1)\n",
    "            ssq = ssq/ torch.sum(ssq)\n",
    "            ssq = transforms.functional.gaussian_blur(ssq,33)\n",
    "    #             print('ssq:', ssq)\n",
    "    \n",
    "            # calculate the weighted L1 loss\n",
    "            err_stack = image_x_p - outputs\n",
    "            chan_weights = 1/torch.std(image_x_p,dim=(2,3))\n",
    "            chan_weights = chan_weights / torch.sum(chan_weights)\n",
    "            chan_weights[0] = 0.1\n",
    "            l1_err_per_chan = torch.mean(torch.abs(err_stack),dim=(2,3))\n",
    "            spectral_weighted_l1 = torch.mean(chan_weights * l1_err_per_chan)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # penalize deviation from zero mean error\n",
    "            loss_zme = torch.mean(torch.mean(err_stack,dim=(2,3))**2)\n",
    "\n",
    "\n",
    "            loss_recon = criterion(image_x_p, outputs)\n",
    "            #loss_recon = torch.mean(ssq*(err_stack**2))\n",
    "\n",
    "            # interchannel correlation loss\n",
    "            loss_zcorr = channelCorrelationLoss(z)\n",
    "            #zdown2 = f.avg_pool2d(z,kernel_size=16,stride=1)\n",
    "            #loss_zcorr = channelCorrelationLoss(zdown2)\n",
    "            \n",
    "            #loss_hoyer = torch.mean(torch.sum(torch.abs(z),dim=1)**2 / (torch.sum((z)**2,dim=1)+0.001))\n",
    "            loss_hoyer = torch.sum(torch.abs(z))**2 / (torch.sum((z)**2)+0.001)\n",
    "            \n",
    "            loss_z_l0 = torch.mean(1.0*(z>0.0))\n",
    "            \n",
    "            # L1 sparsity on normalized stack\n",
    "            #ret = z.max(dim=1,keepdim=True)\n",
    "            #z_normd = z / ret.values\n",
    "            #z_normd[torch.isnan(z_normd)]=0\n",
    "            #print(z_normd.shape)\n",
    "            #print(z_normd)\n",
    "            z_l1 = torch.mean(torch.abs(z))\n",
    "    \n",
    "            # total loss\n",
    "            #loss = loss_recon + lambda_zcorr * loss_zcorr\n",
    "            #loss = spectral_weighted_l1 * loss_zcorr\n",
    "            #loss = loss_recon * loss_zcorr\n",
    "            #loss = loss_recon + 0.01 * loss_zcorr\n",
    "            #loss = spectral_weighted_l1\n",
    "            loss = spectral_weighted_l1+0.001*loss_zcorr\n",
    "            #loss = spectral_weighted_l1+0.001*loss_zcorr + 1e-8*loss_hoyer\n",
    "            #loss = spectral_weighted_l1 + 1e-9 * loss_hoyer + 1e-4*loss_zcorr\n",
    "            #loss = spectral_weighted_l1 + *z_l1\n",
    "            #loss = loss_recon\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #scheduler.step(loss)\n",
    "\n",
    "            train_loss += loss.item()*image_x_p.size(0)\n",
    "            \n",
    "            loss_recon_avg += loss_recon\n",
    "            loss_zcorr_avg += loss_zcorr\n",
    "            \n",
    "            \n",
    "        train_loss = train_loss/len(dataset)\n",
    "        total_loss.append(train_loss)\n",
    "        \n",
    "        loss_recon_avg = loss_recon_avg / len(dataset)\n",
    "        loss_zcorr_avg = loss_zcorr_avg / len(dataset)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #scheduler.step(train_loss)\n",
    "        \n",
    "        # rearrange channels so red has max variance, blue the least\n",
    "        model.indices = channelmsq.argsort(descending=True)\n",
    "        \n",
    "        if epoch%1 == 0:\n",
    "        #if (epoch > 100) and (train_loss == np.min(total_loss)):\n",
    "        #img1 = 0\n",
    "        #img2 = 0\n",
    "            img1, img2 = visualSummary(model,total_loss, model.indices)\n",
    "            print('recon loss: ', loss_recon_avg.item(), ', zcorr loss: ', loss_zcorr_avg.item())\n",
    "        \n",
    "    return total_loss[-1], img1, img2, loss_recon_avg, loss_zcorr_avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_arr = []\n",
    "\n",
    "# number of times the experiment is repeated\n",
    "n_runs = 1\n",
    "\n",
    "\n",
    "nch = len(dataset[0])\n",
    "\n",
    "\n",
    "n_epochs = 50\n",
    "learning_rate = 0.01\n",
    "nch_bottleneck = 2\n",
    "\n",
    "loss_recon_arr = np.zeros(n_runs)\n",
    "loss_zcorr_arr = np.zeros(n_runs)\n",
    "\n",
    "\n",
    "print('Starting training of models on {}'.format(device))\n",
    "n_count = 0\n",
    "models = [Net() for i in range(n_runs)]\n",
    "for i in range(1,n_runs+1):\n",
    "    #model = Net()\n",
    "    loss, img1, img2, loss_recon, loss_zcorr = train_model(models[i-1], n_epochs, dataset, learning_rate)\n",
    "    loss_arr.append((loss, img1, img2))\n",
    "    loss_recon_arr[i-1] = loss_recon\n",
    "    loss_zcorr_arr[i-1] = loss_zcorr\n",
    "    n_count+=1\n",
    "    print('Runs done: {}/{}'.format(n_count, n_runs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze distribution of recovered endmembers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate endmember list\n",
    "wlist = np.zeros((len(models),9,nch_bottleneck))\n",
    "for i,model in enumerate(models):\n",
    "    w = model.getSOEMlayer().weight\n",
    "    w = w[:,model.indices]\n",
    "    w = w.detach().cpu().numpy().squeeze()\n",
    "    wlist[i,:,:] = w\n",
    "    \n",
    "wlist = wlist.swapaxes(2,1).reshape([n_runs,9*nch_bottleneck])\n",
    "wlist[np.isnan(wlist)] = 0\n",
    "\n",
    "# subtract off means of each column\n",
    "wmeans = np.mean(wlist,axis=0)\n",
    "wlistms = wlist - wmeans\n",
    "\n",
    "# singular value decomposition\n",
    "u,s,vh = np.linalg.svd(wlistms)\n",
    "\n",
    "plt.plot(vh[0:3,:].transpose())\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('signal')\n",
    "plt.title('eigenvectors')\n",
    "plt.legend(['1','2','3'])\n",
    "plt.show()\n",
    "\n",
    "pltrange= 0.5\n",
    "\n",
    "# distribution, eigs1 vs 2\n",
    "plt.figure(figsize=(8,8))\n",
    "x = np.linspace(-pltrange,pltrange,128)\n",
    "y = np.linspace(-pltrange,pltrange,128)\n",
    "#z = np.linspace(-pltrange,pltrange,128)\n",
    "X,Y = np.meshgrid(x,y)\n",
    "Z = np.zeros_like(X)\n",
    "xylist = np.vstack([X.ravel(),Y.ravel(),Z.ravel()])\n",
    "kernel = stats.gaussian_kde(u[0:3,:])\n",
    "D = np.reshape(kernel(xylist).T,X.shape)\n",
    "\n",
    "plt.imshow(D,origin='lower',extent=[x[0],x[-1],y[0],y[-1]])                 \n",
    "\n",
    "#plt.imshow(H.T,interpolation='nearest',origin='lower',extent=[xedges[0],xedges[-1],yedges[0],yedges[-1]])\n",
    "plt.scatter(u[0,:],u[1,:],0.5,marker='o',color='white',alpha=0.5)\n",
    "plt.xlim((-pltrange,pltrange))\n",
    "plt.ylim((-pltrange,pltrange))\n",
    "plt.grid()\n",
    "plt.xlabel('eig 1')\n",
    "plt.ylabel('eig 2')\n",
    "plt.title('distribution of all models')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# relative probability of each model\n",
    "kdeint = kernel.integrate_box([-0.5,-0.5,-0.5],[0.5,0.5,0.5])\n",
    "print(kdeint)\n",
    "relprob = kernel.pdf(u[0:3,:])\n",
    "print(u[0:3,:].shape)\n",
    "relprob = relprob / np.sum(relprob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts,edges=np.histogram(loss_recon_arr,128)\n",
    "loss_recon_w = np.sum(relprob*loss_recon_arr)\n",
    "print('probability-weighted recon loss: ', loss_recon_w)\n",
    "loss_recon_ml = edges[np.argmax(counts)]\n",
    "print('most likely recon loss: ', loss_recon_ml)\n",
    "#aic = 9*np.log(loss_recon_ml)+2*nch_bottleneck\n",
    "aic = 9*np.log(loss_recon_ml)+9*nch_bottleneck+3\n",
    "print('AIC: ', aic)\n",
    "\n",
    "plt.plot(edges[1:],counts)\n",
    "plt.vlines(loss_recon_w,0,max(counts))\n",
    "plt.xlabel('reconstruction loss')\n",
    "plt.ylabel('model count')\n",
    "plt.title('reconstruction loss histogram')\n",
    "plt.plot()\n",
    "\n",
    "loss_recon_w = np.sum(relprob*loss_recon_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(relprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts,edges=np.histogram(relprob,128)\n",
    "plt.plot(edges[1:],counts)\n",
    "plt.show()\n",
    "print(np.percentile(relprob,90))\n",
    "print(np.max(relprob))\n",
    "print(np.argwhere(relprob > np.percentile(relprob,90)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate endmembers and abundances based on relative probability weighting of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_z_image_ensembled(ind, models):\n",
    "    nb,ny,nx,nch = img_stack.shape\n",
    "    img = np.zeros((len(models),ny,nx,nch_bottleneck))\n",
    "    for i, model in enumerate(models):\n",
    "        data = img_stack[ind,:,:,:]\n",
    "        data = data[None,:]\n",
    "        data = data.to(device)\n",
    "        out = model.forward_enc(torch.permute(data, (0, 3, 1, 2)))\n",
    "        out = out[0,model.indices,:,:]\n",
    "        out = torch.permute(out, (1,2,0))\n",
    "        img[i] = relprob[i]*out.detach().cpu().numpy()\n",
    "        #img[i] = out.detach().cpu().numpy()\n",
    "        \n",
    "    #img = img/len(models)\n",
    "    #img = np.mean(img,axis=0).squeeze()\n",
    "    img[np.isnan(img)]=0\n",
    "    img = np.sum(img,axis=0).squeeze()\n",
    "    #nbin = 50\n",
    "    #ret = mode((nbin*img).astype(np.int),axis=0)\n",
    "    #img = ret.mode.astype(np.float)/nbin\n",
    "\n",
    "    img_recolor = abundancemapToRGB( img )\n",
    "    return img_recolor\n",
    "\n",
    "def generate_w_ensembled(models):\n",
    "    wlist = np.zeros((len(models),9,nch_bottleneck))\n",
    "    for i,model in enumerate(models):\n",
    "        w = model.getSOEMlayer().weight\n",
    "        w = w[:,model.indices]\n",
    "        w = w.detach().cpu().numpy().squeeze()\n",
    "        w[np.isnan(w)]=0\n",
    "        wlist[i,:,:] = relprob[i] * w\n",
    "        #\n",
    "        \n",
    "    return np.sum(wlist,axis=0)\n",
    "    #return wlist\n",
    "        \n",
    "        \n",
    "tau=np.array([-2,0,0.2,0.4,1,2,4,6,14])\n",
    "w = generate_w_ensembled(models)\n",
    "print(w.shape)\n",
    "alph = 20/len(models)\n",
    "#alph=0.03\n",
    "ax=plt.axes()\n",
    "plotEndmembers(tau,w,ax)\n",
    "ax.set_xlim([-2,14])\n",
    "ax.set_ylim([-0.05,0.6])\n",
    "plt.show()\n",
    "                     \n",
    "\n",
    "plt.figure(figsize=[8,10])\n",
    "plt.imshow(generate_z_image_ensembled(0,models))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=[8,10])\n",
    "plt.imshow(generate_z_image_ensembled(1,models))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=[8,10])\n",
    "plt.imshow(generate_z_image_ensembled(2,models))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=[8,10])\n",
    "plt.imshow(generate_z_image_ensembled(5,models))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endmembers and abundances based on most likely model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_z_image_onemodel(ind, model):\n",
    "    nb,ny,nx,nch = img_stack.shape\n",
    "    data = img_stack[ind,:,:,:]\n",
    "    data = data[None,:]\n",
    "    data = data.to(device)\n",
    "    out = model.forward_enc(torch.permute(data, (0, 3, 1, 2)))\n",
    "    out = out[0,model.indices[0:nch_bottleneck],:,:]\n",
    "    out = torch.permute(out, (1,2,0))\n",
    "    img = out.detach().cpu().numpy()\n",
    "    \n",
    "    img_recolor = abundancemapToRGB( img )\n",
    "    return img_recolor\n",
    "\n",
    "def generate_w_onemodel(model):\n",
    "    w = model.getSOEMlayer().weight\n",
    "    w = w[:,model.indices]\n",
    "    w = w.detach().cpu().numpy().squeeze()\n",
    "    return w\n",
    "\n",
    "ind_ml = np.argmax(relprob)\n",
    "print('most likely model: ', ind_ml)\n",
    "\n",
    "#aic = 9*np.log(loss_recon_arr[ind_ml])+2*nch_bottleneck\n",
    "aic = 9*np.log(loss_recon_arr[ind_ml])+2*(9*nch_bottleneck)\n",
    "print('AIC: ', aic)\n",
    "\n",
    "tau=np.array([-2,0,0.2,0.4,1,2,4,6,14])\n",
    "w = generate_w_onemodel(models[ind_ml])\n",
    "\n",
    "ax=plt.axes()\n",
    "plotEndmembers(tau,w,ax)\n",
    "ax.set_xlim([-2,14])\n",
    "ax.set_ylim([-0.05,0.6])\n",
    "plt.show()\n",
    "                     \n",
    "\n",
    "plt.figure(figsize=[8,10])\n",
    "plt.imshow(generate_z_image_onemodel(0,models[ind_ml]))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=[8,10])\n",
    "plt.imshow(generate_z_image_onemodel(1,models[ind_ml]))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=[8,10])\n",
    "plt.imshow(generate_z_image_onemodel(2,models[ind_ml]))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=[8,10])\n",
    "plt.imshow(generate_z_image_onemodel(5,models[ind_ml]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average top most likely models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_z_image_ensembled(ind, models):\n",
    "    print(len(models))\n",
    "    nb,ny,nx,nch = img_stack.shape\n",
    "    img = np.zeros((len(models),ny,nx,nch_bottleneck))\n",
    "    for i, model in enumerate(models):\n",
    "        data = img_stack[ind,:,:,:]\n",
    "        data = data[None,:]\n",
    "        data = data.to(device)\n",
    "        out = model.forward_enc(torch.permute(data, (0, 3, 1, 2)))\n",
    "        out = out[0,model.indices[0:nch_bottleneck],:,:]\n",
    "        out = torch.permute(out, (1,2,0))\n",
    "        img[i] =out.detach().cpu().numpy()\n",
    "        #img[i] = out.detach().cpu().numpy()\n",
    "        \n",
    "    #img = img/len(models)\n",
    "    img = np.mean(img,axis=0).squeeze()\n",
    "    img[np.isnan(img)]=0\n",
    "    #mg = np.median(img,axis=0).squeeze()\n",
    "    #nbin = 50\n",
    "    #ret = mode((nbin*img).astype(np.int),axis=0)\n",
    "    #img = ret.mode.astype(np.float)/nbin\n",
    "    \n",
    "    ny,nx,nch = img.shape\n",
    "    img_recolor = np.zeros((ny,nx,3))\n",
    "    img_recolor[:,:,0] += img[:,:,0]\n",
    "    img_recolor[:,:,1] += img[:,:,0]\n",
    "    img_recolor[:,:,1] += img[:,:,1]\n",
    "    img_recolor[:,:,2] += img[:,:,1]\n",
    "    img_recolor[:,:,2] += img[:,:,2]\n",
    "    img_recolor[:,:,0] += img[:,:,2]\n",
    "    if nch_bottleneck > 3:\n",
    "        img_recolor[:,:,0] += img[:,:,3]\n",
    "    #img_recolor[:,:,1] += img[:,:,4]\n",
    "    return img_recolor\n",
    "\n",
    "def generate_w_ensembled(models):\n",
    "    wlist = np.zeros((len(models),9,nch_bottleneck))\n",
    "    for i,model in enumerate(models):\n",
    "        w = model.getSOEMlayer().weight\n",
    "        w = w[:,model.indices]\n",
    "        w = w.detach().cpu().numpy().squeeze()\n",
    "        w[np.isnan(w)]=0\n",
    "        wlist[i,:,:] = w\n",
    "        #\n",
    "        \n",
    "    return np.mean(wlist,axis=0)\n",
    "    #return wlist\n",
    "        \n",
    "minpr = np.percentile(relprob,90)\n",
    "models_sel = []\n",
    "for i in range(n_runs):\n",
    "    if relprob[i] >= minpr:\n",
    "        models_sel.append(models[i])\n",
    "\n",
    "print(len(models_sel))\n",
    "        \n",
    "tau=np.array([-2,0,0.2,0.4,1,2,4,6,14])\n",
    "w = generate_w_ensembled(models_sel)\n",
    "print(w.shape)\n",
    "alph = 20/len(models)\n",
    "#alph=0.03\n",
    "ax=plt.axes()\n",
    "ax.set_facecolor('black')\n",
    "plt.plot(tau,w[:,0],color='yellow')\n",
    "plt.plot(tau,w[:,1],color='cyan')\n",
    "plt.plot(tau,w[:,2],color='magenta')\n",
    "if nch_bottleneck > 3:\n",
    "    plt.plot(tau,w[:,3],color='red')\n",
    "    #\n",
    "#for i in range(len(models)):\n",
    "#    plt.plot(tau,w[i,:,0],color='yellow',alpha=alph)\n",
    "#    plt.plot(tau,w[i,:,1],color='cyan',alpha=alph)\n",
    "#    plt.plot(tau,w[i,:,2],color='magenta',alpha=alph)\n",
    "    #plt.plot(tau,w[i,:,3],color='red',alpha=alph)\n",
    "    #plt.plot(tau,w[i,:,4],color='green',alpha=2*alph)\n",
    "ax.set_xlim([-2,14])\n",
    "ax.set_ylim([-0.05,0.6])\n",
    "plt.show()\n",
    "                     \n",
    "\n",
    "plt.figure(figsize=[8,10])\n",
    "plt.imshow(generate_z_image_ensembled(0,models_sel))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=[8,10])\n",
    "plt.imshow(generate_z_image_ensembled(1,models_sel))\n",
    "plt.show()\n",
    "\n",
    "#plt.figure(figsize=[8,10])\n",
    "#plt.imshow(generate_z_image_ensembled(2,models))\n",
    "#plt.show()\n",
    "\n",
    "#plt.figure(figsize=[8,10])\n",
    "#plt.imshow(generate_z_image_ensembled(5,models))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "permobj = permutations([0,1,2,3])\n",
    "nperms = np.math.factorial(nch_bottleneck)\n",
    "perms = np.zeros((nperms,nch_bottleneck))\n",
    "for iperm,perm in enumerate(permobj):\n",
    "    perms[iperm,:] = perm\n",
    "    \n",
    "model = models[1]\n",
    "\n",
    "w = model.getSOEMlayer().weight\n",
    "wlist = np.zeros((nperms,9,nch_bottleneck))\n",
    "\n",
    "for iperm,perm in enumerate(perms):\n",
    "    wlist[iperm,:,:] = w[:,perm].squeeze().cpu().detach().numpy()\n",
    "    \n",
    "wlist = wlist.swapaxes(2,1).reshape([nperms,9*nch_bottleneck])\n",
    "wlist[np.isnan(wlist)] = 0\n",
    "    \n",
    "plt.imshow(wlist)\n",
    "plt.ylabel('permutation number')\n",
    "plt.xlabel('pump-probe delay index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wref = models[ind_ml].getSOEMlayer().weight[:,models[ind_ml].indices].cpu().detach().numpy().squeeze()\n",
    "wref=wref[None,:]\n",
    "wref = wref.swapaxes(2,1).reshape([1,9*nch_bottleneck])\n",
    "wref.shape\n",
    "plt.plot(wref.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_matching_perm = np.argmax(np.sum(wlist * wref,1))\n",
    "print(ind_matching_perm)\n",
    "perms[ind_matching_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perms[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvarsrt = model.getSOEMlayer().weight[:,model.indices].cpu().detach().numpy().squeeze()\n",
    "wvarsrt=wvarsrt[None,:]\n",
    "wvarsrt = wvarsrt.swapaxes(2,1).reshape([1,9*nch_bottleneck])\n",
    "\n",
    "plt.plot(wref.T)\n",
    "plt.plot(wlist[12,:].T)\n",
    "plt.plot(wvarsrt.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference model (most likely)\n",
    "wref = models[ind_ml].getSOEMlayer().weight[:,models[ind_ml].indices].cpu().detach().numpy().squeeze()\n",
    "wref=wref[None,:]\n",
    "wref = wref.swapaxes(2,1).reshape([1,9*nch_bottleneck])\n",
    "\n",
    "# permutations set-up\n",
    "permobj = permutations([0,1,2,3])\n",
    "nperms = np.math.factorial(nch_bottleneck)\n",
    "perms = np.zeros((nperms,nch_bottleneck))\n",
    "for iperm,perm in enumerate(permobj):\n",
    "    perms[iperm,:] = perm\n",
    "    \n",
    "# iterate through all models\n",
    "for model in models:\n",
    "\n",
    "    w = model.getSOEMlayer().weight\n",
    "    wlist = np.zeros((nperms,9,nch_bottleneck))\n",
    "\n",
    "    # generate permutations of endmembers for this model\n",
    "    for iperm,perm in enumerate(perms):\n",
    "        wlist[iperm,:,:] = w[:,perm].squeeze().cpu().detach().numpy()\n",
    "\n",
    "    wlist = wlist.swapaxes(2,1).reshape([nperms,9*nch_bottleneck])\n",
    "    wlist[np.isnan(wlist)] = 0\n",
    "    \n",
    "    # find permutation that best matches the reference model\n",
    "    ind_matching_perm = np.argmax(np.sum(wlist * wref,1))\n",
    "    \n",
    "    # store best-matching permutation in the model\n",
    "    model.indices = perms[ind_matching_perm]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_z_image_std(ind, models):\n",
    "    print(len(models))\n",
    "    nb,ny,nx,nch = img_stack.shape\n",
    "    img = np.zeros((len(models),ny,nx,nch_bottleneck))\n",
    "    for i, model in enumerate(models):\n",
    "        data = img_stack[ind,:,:,:]\n",
    "        data = data[None,:]\n",
    "        data = data.to(device)\n",
    "        out = model.forward_enc(torch.permute(data, (0, 3, 1, 2)))\n",
    "        out = out[0,model.indices[0:nch_bottleneck],:,:]\n",
    "        out = torch.permute(out, (1,2,0))\n",
    "        img[i] =out.detach().cpu().numpy()\n",
    "        #img[i] = out.detach().cpu().numpy()\n",
    "        \n",
    "    #img = img/len(models)\n",
    "    img = np.std(img,axis=0).squeeze()\n",
    "    img[np.isnan(img)]=0\n",
    "    #mg = np.median(img,axis=0).squeeze()\n",
    "    #nbin = 50\n",
    "    #ret = mode((nbin*img).astype(np.int),axis=0)\n",
    "    #img = ret.mode.astype(np.float)/nbin\n",
    "    \n",
    "    ny,nx,nch = img.shape\n",
    "    img_recolor = np.zeros((ny,nx,3))\n",
    "    img_recolor[:,:,0] += img[:,:,0]\n",
    "    img_recolor[:,:,1] += img[:,:,0]\n",
    "    img_recolor[:,:,1] += img[:,:,1]\n",
    "    img_recolor[:,:,2] += img[:,:,1]\n",
    "    img_recolor[:,:,2] += img[:,:,2]\n",
    "    img_recolor[:,:,0] += img[:,:,2]\n",
    "    if nch_bottleneck > 3:\n",
    "        img_recolor[:,:,0] += img[:,:,3]\n",
    "    #img_recolor[:,:,1] += img[:,:,4]\n",
    "    return img_recolor\n",
    "\n",
    "plt.figure(figsize=[8,10])\n",
    "plt.imshow(generate_z_image_std(0,models_sel))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=[8,10])\n",
    "plt.imshow(generate_z_image_std(1,models_sel))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for x in loss_arr:\n",
    "    print(\"Loss: \", x[0])\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(x[1])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(x[2])\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_boxplot(dataList, expNameList, yRange, metric, dataNum, save=False):\n",
    "    plt.figure(figsize=(18,6))\n",
    "    plt.boxplot(dataList)\n",
    "    plt.ylim(yRange)\n",
    "    plt.grid()\n",
    "    plt.xticks([i+1 for i in range(dataNum)], [expNameList[i] + ': ' + str(np.round(np.mean(dataList[i]),6)) for i in range(len(dataList))])\n",
    "    if str(metric) == 'PSNR':\n",
    "        plt.ylabel(str(metric) + ' dB')\n",
    "    else:\n",
    "        plt.ylabel(str(metric))\n",
    "    plt.title(str(metric) + ' boxplots for different initialization techniques')\n",
    "    if save:\n",
    "        plt.savefig('Boxplot' + str(metric), dpi=100, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataList = [loss_arr_xu, loss_arr_u, loss_arr_normal, loss_arr_constant, loss_arr_xn, loss_arr_ku, loss_arr_kn]\n",
    "expNameList = ['xavier_uniform', 'uniform', \"normal\", 'constant', 'xavier normal', 'kaiming uniform', 'kaiming normal']\n",
    "basic_boxplot(dataList, expNameList, [0, 0.002], 'Total Loss', 7, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_arr = []\n",
    "\n",
    "# number of times the experiment is repeated\n",
    "n_runs = 1\n",
    "n_epochs = 200\n",
    "learning_rate = 1e-2\n",
    "nch_bottleneck = 3\n",
    "\n",
    "print('Starting training of models on {}'.format(device))\n",
    "n_count = 0\n",
    "patch_arr = [20, 40, 60, 80, 100, 150, 200, 250]\n",
    "for patch_size in patch_arr:\n",
    "    print('Patch Size:', patch_size)\n",
    "    model = Net()\n",
    "    loss, img1, img2 = train_model(model, n_epochs, img_stack, learning_rate, patch_size)\n",
    "    loss_arr.append((loss, img1, img2))\n",
    "    n_count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
